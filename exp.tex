\section{Experimental Evaluation}
\label{sec:exp}

In order to demonstrate the efficacy of our history-inclusion based
approximation to observational refinement, we argue that our $k$-approximation:
\begin{itemize}

  \item uncovers most violations with small values of $k$, and

  \item can be efficiently implemented, and vastly outperforms linearizability
  checking.

\end{itemize}

To argue both points, we have studied the concurrent data structure
implementations of Scal\footnote{Scal High-Performance Multicore-Scalable
Computing~\url{http://scal.cs.uni-salzburg.at}}, which include both LIFO- and
FIFO-based container objects. Some of these objects, such as the Michael-Scott
Queue~\cite{conf/podc/MichaelS96}, are meant to preserve observational
refinement\footnote{More precisely, they have been designed to be
linearizable.}, while others, such as Kirsch et al.'s
$k$-FIFO~\cite{conf/pact/KirschLP13}, are meant to preserve weaker properties.
For our experiments we have used Scal's C++ implementations without
modification, except to annotate methods with a fixed set of possible
preemption points, e.g.,~preceding accesses to shared storage.

To make the following comparisons, we have developed a tool for enumerating a
(large) number of alternate executions involving a limited number of object
method invocations. We execute each operation on a separate thread, and ensure
that all thread schedules up to a given number $n \in \<Nats>$ of thread
preemptions (at specified preemption points) are executed, similarly to
Microsoft's Chess tool~\cite{conf/osdi/MusuvathiQBBNN08}. With $n=0$
preemptions, there is only one schedule/execution, though the number of
schedules/executions grows exponentially as $n$ increases. For instance, with
our annotation of preemptions in Scal's Michael-Scott Queue, increasing
$n=1..5$ yields $33$, $612$, $8343$, $95434$, and $930141$ schedules, which are
executed at a rate of roughly one million schedules per minute on a MacBook Pro
2.6GHz Intel Core i5 machine.


\subsection{Coverage of Violations}

To show that most violations to observational refinement are uncovered by our
history inclusion approximation for small values of $k$, we have measured the
number of explored histories which are not linearizable, versus the number of
explored histories $h$ for which $A_k(h) |= \lnot @Y$. We use linearizability
as a metric for $h \in H(L)$, due to the equivalence of Section~\ref{sec:lin},
and since algorithms for computing linearizability are well
known~\cite{conf/pldi/BurckhardtDMT10}.

Figure~\ref{fig:data:coverage} shows that as the sample size of executions per
number of operations increases, number of violating histories $h$ for which
$A_k(h) |= \lnot @Y$ also increases. Furthermore, as the number of explored
histories increases beyond a certain point, the vast majority of violations $h$
are also detected by some explored $A_k(h') \preceq h$.

TODO DESCRIBE THIS BETTER AND MAKE IT CLEARER

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{figures/coverage-bkq-2-barriers}
  \caption{Coverage of violations.}
  \label{fig:data:coverage}
\end{figure}

\subsection{Efficiency}

Figure~\ref{fig:data:runtime} compares the runtime overhead of our
operation-counting instrumentation for $k=2$, versus a linearization-based
instrumentation, sampling executions with up to $20$ operations on Scal's
nonblocking Michael-Scott queue $L_\mathrm{msq}$. Since computing the set of
sequential histories $\ker H(L_\mathrm{msq})$ over $n$ operations becomes
prohibitively expensive as $n$ increases --- already surpassing a timeout of
$5$m for $n=7$ --- our measurements bypass the computation of $\ker
H(L_\mathrm{msq})$ entirely, and simply enumerate the linearizations of $H(e)$
for each execution $e$ without checking their inclusion $\ker
H(L_\mathrm{msq})$. Despite our best-effort-efficiency implementation of this
enumeration, one observes the cost incurred by this exponential-time algorithm:
as the number of operations increases --- thus exponentially increasing the
number linearizations --- performance plummets. With only 20 operations,
instrumentation overhead is nearly 100,000\%. Operation counting avoids this
dramatic overhead; though we have not optimized our implementation, we observe
that runtime overhead stays within 30\%.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{figures/lin-vs-counting-time}
  \caption{Comparison of runtime overhead between linearization-based monitoring
    and operation counting ($k=2$) for up to $20$ operations. Each data point
    measures runtime on a logarithmic scale, normalized to unmonitored
    execution time, over all executions up to $3$ preemptions on Scal's
    nonblocking Michael-Scott queue with $i$ enqueue operations and $j$ dequeue
    operations. The x-axis is ordered by increasing $i+j$, for $i$ and $j$
    ranging over $1..10$. Times do not include pre-calculation of sequential
    histories for linearization-based monitoring.
  }
  \label{fig:data:runtime}
\end{figure}
