%!TEX root = draft.tex
\section{Introduction}

Efficient implementations of concurrent objects such as semaphores, locks, and
atomic collections including stacks and queues are vital to modern computer
systems. Programming them is however error prone. To minimize synchronization
overhead between concurrent object-method invocations, implementors avoid
blocking operations like lock acquisition, allowing methods to execute
concurrently. However, concurrency risks unintended inter-operation
interference, and risks conformance to reference implementations. Conformance
is formally captured by \emph{observational refinement}: given two libraries
$L_1$ and $L_2$ implementing the methods of some concurrent object, we say
$L_1$ \emph{refines} $L_2$ if and only if every computation of every program
using $L_1$ would also be possible were $L_2$ used instead.

Verifying observational refinement is intrinsically hard, and generally
undecidable~\cite{conf/esop/BouajjaniEEH13}. Here we develop a tractable
algorithmic approach to detecting refinement violations, in two parts.

The first part, outlined in Section~\ref{sec:intro:histories}, establishes a
foundational characterization of refinement in terms of sets of so-called
\emph{histories}. Histories abstract executions into the happens-before
(partial) order between object-method invocations. We show that refinement
between libraries is equivalent to a history-set inclusion problem.
Consequently, violations correspond to excluded histories.

Since refinement-violation detection for even a single execution is
NP-hard~\cite{journals/siamcomp/GibbonsK97}, the second part, outlined in
Section~\ref{sec:intro:approx}, develops a novel approximation for refinement
checking. We demonstrate that our approach is feasible, leading to scalable
refinement-violation-detection algorithms. The insight behind our approximation
exploits fundamental properties of the histories arising from shared-memory
concurrent executions: they are a special class of partial orders called
interval orders. Such orders admit convenient representations leading to
efficient automation, and reveal a useful parameter for refining our
approximation. In practice we find that even coarse approximations uncover
refinement violations, and can be implemented much more efficiently than
existing approaches.


\subsection{Characterizing Observational Refinement}
\label{sec:intro:histories}

Naturally, automating observational refinement verification is challenging. The
most immediate obstacle arises from the quantification over the infinitely-many
possible library-client programs: a library $L_1$ refines another library $L_2$
if every observation of every client program using $L_1$ is also admitted using
$L_2$. Our first contribution is to provide a \emph{precise} characterization
of refinement as a set-inclusion problem, defined independently from libraries'
execution contexts, between the partial orders of operations admitted by each
library. More precisely, we associate to each execution $e$ a partial order
$H(e)$ on its object-method invocations, called a \emph{history}. An operation
$o_1$ is considered to happen before an operation $o_2$ in $H(e)$ if $o_1$
completes before $o_2$ is invoked in $e$. We prove that a library $L_1$ refines
another $L_2$ if and only if the set $H(L_1)$ of $L_1$'s histories
(i.e.,~associated with $L_1$'s executions) is included in $H(L_2)$.

This characterization is a fundamental result that offers a fresh view for
reasoning about refinement. Thus far, the principal approach for checking
observational refinement in the literature is based on
\emph{linearizability}~\cite{journals/toplas/HerlihyW90}, requiring that
operations of every execution of $L_1$ can be permuted into a serial execution
of $L_2$ while preserving the return-call order between operations. While
linearizability implies observational
refinement~\cite{journals/tcs/FilipovicORY10}, we demonstrate that the converse
does not generally hold. To shed light on the subtle relationship between these
concepts, we investigate the link between history inclusion and
linearizability. We prove that when $L_2$ is atomic, which is often the
case for reference implementations, history inclusion between $L_1$ and
$L_2$, and therefore observational refinement, is equivalent to linearizability.


\subsection{Approximating Observational Refinement}
\label{sec:intro:approx}

Besides offering a fresh perspective on observational refinement, our
characterization leads to an efficient approximation-based approach for
detecting refinement violations, exploiting fundamental properties of
library executions and their histories. We consider a \emph{weakening preorder}
$\preceq$ on histories as a means for approximation: a history $h_1$ is
\emph{weaker} than another history $h_2$, written $h_1 \preceq h_2$,
essentially if $h_1$ is obtained from $h_2$ by relaxing order constraints. We
show that if a library $L$ admits a history $h$, then $L$ also admits every
weaker history $h' \preceq h$. Our approximation principle considers
weakenings $A(h) \preceq h$ of histories $h\in H(L_1)$, such that checking
$A(h) \in H(L_2)$ is \emph{tractable}. If $A(h) \not\in H(L_2)$ then $h \not\in
H(L_2)$, and thus a violation is found.

The challenge is to design a parameterized approximation $A_k$, for $k \in
\mathbb{N}$, such that $A_k(h) \in H(L_2)$ is decidable in \emph{polynomial
time} in the size of $h$. The approximation should also be \emph{complete}, in
the sense that for any history $h$, there exists $k \in \<Nats>$ such that $h
\preceq A_k(h)$, ensuring that any violation can be captured with a large
enough parameter value. Finally, the approximation should be easy to implement,
and catch violations with small parameter values.

% \paragraph{Parameterized Approximation by Bounded Interval Length}

Our approximation scheme exploits a fundamental property of shared-memory
library executions: their histories are \emph{interval orders}, a special case
of partial orders which admit \emph{canonical representations} in which each
operation $o$ is mapped to a positive-integer-bounded interval $I(o)$. An
operation $o_1$ happens before another operation $o_2$ if and only if the
interval $I(o_1)$ ends before $I(o_2)$ begins~\cite{phd/Greenough76}. Interval
orders are equipped with a natural notion of \emph{length}, which corresponds
to the smallest integer constant for which an interval mapping exists. Our
approximation $A_k$ maps each history $h$ to a weaker history $A_k(h)$ of
interval length at most $k$.

Bounded-interval-length orders admit a convenient representation of histories
using counting: each interval is represented by a counter whose value reflects
the number of operations spanning that interval. Such a representation
conveniently opens the door to symbolic manipulation of history sets using
arithmetic constraints, which we describe using a simple \emph{operation
counting logic (OCL)}. We demonstrate that this logic has a polynomial-time
model-checking problem, and is suitable for reasoning about commonly-used
concurrent object libraries including atomic collections like stacks and
queues. We also demonstrate that OCL formul\ae can be systematically
constructed for a broad class of concurrent objects.

Moreover, counting-based representations can be efficiently monitored in
polynomial-time and space using simple counter increments and decrements at the
precise moments when operations begin and end. By maintaining a
$k$-interval-length approximation $A_k(H(e))$ of an execution $e$, we
effectively reduce our approximate refinement-checking problem to a
\emph{safety verification} problem by periodically checking whether $A_k(H(e))
|= @Y$, where $@Y$ is an OCL formula characterizing the $k$-interval-length
histories of $H(L_2)$.

Empirically, we demonstrate that our approach is effective in both
dynamic-checking and static-checking contexts. Used in the dynamic setting, we
maintain relatively-low runtime overhead which does not increase in the length
of executions. Our approach scales far beyond the existing approaches based on
linearizability, in which enumerating linearizations explodes exponentially in
the length of executions. Furthermore, our approximation $A_k$ is well-suited
for catching refinement violations with small parameter values: violations are
most often detected with $k \le 2$, and almost always with $k \le 4$. In fact,
we even prove that many violations to atomic collection objects including
stacks and queues can always be caught with $k \le 3$. In the static-checking
context, our counting-based representation allows us to leverage off-the-shelf
SAT/SMT-based symbolic program exploration tools including
CSeq~\cite{conf/ase/FischerIP13} (with backend
CBMC~\cite{conf/tacas/KroeningT14}) and SMACK~\cite{conf/cav/RakamaricE14}
(with backend Corral~\cite{conf/cav/LalQL12}) to discover refinement violations.

\subsection{Summary of Contributions}

This work makes the following contributions:
\begin{itemize}

  \item A characterization of observational refinement as a
  history-set-inclusion problem (\S\ref{sec:histories}), and a proof of
  equivalence with linearizability for atomic reference implementations
  (\S\ref{sec:lin}).

  \item An under-approximation for detecting observational refinement
  violations based on a weakening preorder on histories, exploiting the fact
  that library histories are interval orders (\S\ref{sec:counting}).

  \item An efficient implementation of our approximation using counters.
  Specifically, we reduce refinement checking to safety-property checking
  (\S\ref{sec:counting:monitor}) using symbolic arithmetic representations of
  bounded-interval-length history sets (\S\ref{sec:counting:logic}),
  demonstrate cut-off bounds for atomic-collection objects
  (\S\ref{sec:containers}), and develop an automatic construction of counting
  representations (\S\ref{sec:regular}).

  \item Experimental validation of our approximation-based approach in both
  dynamic-checking and static-checking settings (\S\ref{sec:exp}).

\end{itemize}
