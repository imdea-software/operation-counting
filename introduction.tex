%!TEX root = draft.tex
\section{Introduction}

Efficient implementations of concurrent objects such as semaphores, locks,
atomic registers, and data structures such as stacks and queues, are essential
to modern computing. Programming them is however error prone. In order to
minimize synchronization overhead between concurrent object invocations,
implementors avoid blocking operations such as lock acquisition, allowing
operations to be concurrently intertwined. Such intertwining risks unexpected
interference between operations, and risks breaking conformance to reference
implementations. Conformance is formally captured by the concept of
\emph{observational refinement}: given two libraries $L_1$ and $L_2$
implementing the operations of some concurrent object, we say $L_1$
\emph{refines} $L_2$ if and only if every computation of every program $P$
using $L_1$ would also be possible were $P$ using $L_2$ instead. The challenge
we address in this paper is to provide a tractable algorithmic approach for
checking observational refinement.

Verifying observational refinement is an intrinsically hard problem, and is
undecidable in general. The contribution of this work is in developing a
tractable approach for detecting refinement violations, and is divided into two
main parts.

In the first part, outlined in Section~\ref{sec:intro:histories}, we establish
a foundational characterization of observational refinement in terms of sets of
so-called \emph{histories}; histories abstract concurrent executions into the
happens-before (partial-order) relation between invoked object methods. We
demonstrate that refinement between libraries is equivalent to a containment
problem between sets of histories, and a violation to refinement corresponds to
history-set inclusion problem. In fact, even checking whether the history of a
single execution belongs to a given set is
NP-hard~\cite{journals/siamcomp/GibbonsK97}.

Motivated by the aforementioned hardness results, in the second part, outlined
in Section~\ref{sec:intro:approx}, we develop a novel parameterized
approximation for refinement checking, and demonstrate that our approach is
feasible, leading to scalable and efficient algorithms for detecting refinement
violations. The insight behind our approximation exploits fundamental
properties of the histories arising from shared-memory concurrent executions:
they are a special class of partial orders called interval orders. Such orders
admit convenient representations leading to efficient automation, and reveal a
useful measure for the parameter of our approximation. In practice we find that
coarse approximations uncover refinement violations, and can be implemented
much more efficiently than existing approaches.

\subsection{Characterizing Observational Refinement}
\label{sec:intro:histories}

Naturally, automating the verification of observational refinement is quite
challenging. The most immediate obstacle arises from the quantification over
the infinitely many possible library-client programs: a library $L_1$ refines
another library $L_2$ if every observation of every client program using $L_1$
is also admitted using $L_2$. Our first contribution is to provide a
\emph{precise} characterization of refinement as a set-inclusion problem,
defined independently from their execution contexts, between the partial orders
of operations admitted by each library. More precisely, we associate to each
execution $e$ a partial order $H(e)$ on its object method invocations called a
\emph{history}. An operation $o_1$ is considered to happen before an operation
$o_2$ in $H(e)$ if $o_1$ completes before $o_2$ is invoked in $e$. We prove
that a library $L_1$ refines another library $L_2$ if and only if the set
$H(L_1)$ of $L_1$'s histories (i.e.,~associated with $L_1$'s executions) is
included in the set $H(L_2)$ of $L_2$'s histories.

This characterization is a fundamental result that offers a fresh view for
reasoning about the refinement problem. Indeed, the principal approach for
tackling the problem of checking observational refinement in the literature is
based on checking \emph{linearizability}~\cite{journals/toplas/HerlihyW90},
which requires that every execution in $L_1$ can be reordered into an execution
of $L_2$ while preserving the order between return and call actions. While
linearizability implies observational
refinement~\cite{journals/tcs/FilipovicORY10}, we show that the converse does
not hold in general. In order to shed light on the subtle relationship between
these concepts, we investigate the links between history inclusion and
linearizability. We prove that, interestingly, when $L_2$ is atomic, which is
typically the case for reference implementations as mentioned above, history
inclusion, and therefore observational refinement, between $L_1$ and $L_2$ is
equivalent to linearizability.

As we will see in the sequel, besides being a useful semantical means for
reasoning about observational refinement, this characterization of the
refinement leads to an efficient and powerful approach for detecting refinement
violations.

\subsection{Approximating Observational Refinement}
\label{sec:intro:approx}

\paragraph{Parameterized approximation schema}

The approach we introduce in this paper is based on fundamental properties of
library executions and their histories. The basic idea is to consider a notion
of \emph{weakening pre-order} $\preceq$ on histories as a means for
approximation: A history $h_1$ is \emph{weaker} than another history $h_2$,
written $h_1 \preceq h_2$, if $h_1$ is obtained from $h_2$ by relaxing some of
its order constraints. We prove that if $h$ is a history of a library $L$ then
every weaker history $h'\preceq h$ is also a history of $L$. This leads to the
approximation principle, which consists in considering for histories $h\in
H(L_1)$ approximations $h' \preceq h$, such that checking $h' \in H(L_2)$ is
\emph{tractable}. If $h' \not\in H(L_2)$, then we also have $h \not\in H(L_2)$,
and therefore a refinement violation is found.

So, the challenge we undertake is to provide an approximation schema based on
defining a series of functions $A_k$, parameterized with $k \in \mathbb{N}$,
such that for every $h$, we have (1) $A_k (h) \preceq h$, and (2) the test
$A_k(h) \in H(L_2)$ is decidable in \emph{polynomial time} (w.r.t. size of
$h$). Moreover, the schema should be \emph{complete} in the sense that there
must be a $k$ such that $h \preceq A_k(h)$, which means that if a violation
exists, it will be captured for a large enough parameter. Finally, and quite
importantly, we seek for an approximation schema that is easy to implement, and
which is able to catch refinement violations with small parameter values.

\paragraph{Bounded interval-length histories}

We provide such an approximation schema, exploiting a fundamental property of
the executions of \emph{shared-memory} libraries: We show that histories of
such executions are \emph{interval orders}. These orders admit \emph{canonical
representations} where each element $o$ is mapped to an integer-bounded
interval $I(o)$ such that for every two elements $o_1$ and $o_2$, $o_1$ is
before $o_2$ if and only if $I(o_1)$ ends before $I(o_2)$
starts~\cite{phd/Greenough76}. Also, interval orders have a notion of
\emph{length} which corresponds to the maximal upper-bound of an interval in
their canonical representation.

This leads us to the definition of a parameterized approximation schema where
the parameter $k$ corresponds to the notion of length mentioned above: For each
$k \in \mathbb{N}$, the function $A_k$ maps each history $h$ to a
($\preceq$-)weaker history $h'$ of interval-length at most $k$.

\paragraph{Reduction to reachability using counting representations}

We show that interval-length bounding is a tractable approach for refinement
checking, and that it can be implemented efficiently. A key idea for that is to
use \emph{counting representations} for bounded interval-length histories: each
interval is represented by a counter corresponding to the number of elements
mapped to this interval in the canonical representation. Indeed, representing
histories as vectors of integers opens the door to symbolic manipulation of
sets of histories using arithmetical constraints. In fact, we introduce for
that purpose a simple logic, called Operation Counting Logic (OCL), that is
suitable for reasoning about libraries implementing common concurrent objects,
and for which checking if a given history satisfies a formula can be done in
\emph{polynomial time}.

Moreover, counting representations provide a simple way for implementing a
monitor $P_k$ that tracks histories of interval-length at most $k$. In fact, we
define a \emph{polynomial time} algorithm that, given an execution, builds a
($k$-bounded interval-length) approximation history of it. Therefore, bounded
interval-length refinement checking between $L_1$ and $L_2$ can be reduced to a
\emph{reachability (or invariant) checking} problem in $P_k$ composed with
$L_1$, provided that the set of histories $A_k(H(L_2))$ is effectively defined
in OCL. We show that this is the case for reference implementations of typical
concurrent objects such as stacks and queues, and that these OCL formulas can
be constructed systematically for a wide class of objects.

\paragraph{Demonstrating feasibility}

We demonstrate in the paper that our approach is feasible both with a dynamic
and a static state space exploration strategy.

In the dynamic case, we show experimentally two remarkable facts. First, our
approach is \emph{scalable}: its overhead is low and does not increase with the
length of computations, whereas the overhead of the standard approach (used in
existing tools such as Line-Up~\cite{conf/pldi/BurckhardtDMT10}) that is based
on enumerating linearizations of executions explodes exponentially. Second, our
approach is \emph{efficient} and well suited for catching refinement
violations: most of these violations in practice are detected with small
bounds, i.e.,~for $k$ ranging from 0 to $2$, and relatively few (marginal)
cases need greater bounds such as 3 or 4. On this issue, we were actually able
to prove that for stacks and queues, refinement checking for order constraints
can actually be reduced (without loss of completeness) to bounded refinement
checking with small cut-off bounds, namely 3 and 2 respectively.

In the static case, using the fact that sets of histories can be represented
using arithmetical constraints, we can, for the first time, check the existence
of refinement violations using existing tools for reachability analysis of
concurrent programs such as CSeq~\cite{conf/ase/FischerIP13} (with backend
CBMC~\cite{conf/tacas/KroeningT14}) and SMACK~\cite{conf/cav/RakamaricE14}
(with backend Corral~\cite{conf/cav/LalQL12}) that are based on efficient
symbolic encodings of sets of computations and the use of SMT solvers.

\subsection{Summary of Contributions}

This work makes following contributions:
\begin{itemize}

  \item A characterization of observational refinement as a history inclusion
  problem (\S\ref{sec:histories}), and an proof of equivalence with
  linearizability for atomic reference implementations (\S\ref{sec:lin}).

  \item An under-approximation for detecting observational refinement
  violations based on a weakening pre-order on histories, exploiting the fact
  that histories are interval orders (\S\ref{sec:counting}).

  \item An efficient implementation of this approximation using counting
  representations. Specifically, a reduction to a reachability problem
  (\S\ref{sec:counting:monitor}) using arithmetic-based symbolic
  representations of sets of interval-length bounded histories
  (\S\ref{sec:counting:logic}), cut-off bounds for representations
  collection-based data structures (\S\ref{sec:containers}), and a procedure
  for automatic generation of these representations (\S\ref{sec:regular}).

  \item Experimental demonstration of the efficiency and scalability of our
  approach both in dynamic and static analysis settings (\S\ref{sec:exp}).

\end{itemize}
